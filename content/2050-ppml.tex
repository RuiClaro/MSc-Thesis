%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Privacy-Preserving Machine Learning}
\label{sec:PrivacyPreservingMachineLearning}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


In the context of Data Mining, Machine Learning techniques come as an important addition to the data processing step. An example of that is the \textit{Classification} method. Classification is described by a two-step process, in which a classification algorithm is employed to build a classifier for the data by analyzing a training set made of tuples of data and their associated labels, and then the classifier is used to predict class labels for new data. As such, because the large size of the datasets produced in Big Data operations, classification algorithms have a large quantity of data to learn from, making them less prone to erroneous classification of new data.

The conjunction between Machine Learning and privacy-preserving comes from the need to do knowledge learning over large datasets, while also maintaining protection over the privacy of the data, without degrading the quality of data by using anonymization techniques.

In the field of Machine Learning, we can identify a number of algorithms that can be used in Data Mining. In Table \ref{table:ppml1}, we list some of them, giving a brief description, and identifying a privacy-preserving technique that has been implemented with it.

\begin{table}[H]
\centering
\caption{\ac{PPML} algorithms.}
\label{table:ppml1}
\begin{tabular}{|p{2.3cm}|p{5cm}|p{3.7cm}|l|}
\hline
\textbf{Machine Learning Algorithm} & \textbf{Short summary} & \textbf{Privacy-Preserving Technique} 
& \textbf{Reference} \\ \hline
Decision Tree & Protocol for distributed learning of decision-tree classifiers. & \ac{SMPC} & \cite{brickell2009privacy} \\ \hline
Naive Bayes & Differentially private naive Bayes classifier. Centralized access to the dataset. & \ac{DP}   & 
\cite{vaidya2013differentially} \\ \hline
\acs{SVM}  &Algorithm for support vector machine classification over vertically partitioned data. & \ac{SMPC} &   
\cite{yu2006privacy} \\ \hline
\acs{k-NN}  & Nearest neighbors of records in horizontally distributed data. & \ac{SMPC}  &
\cite{shaneck2006privacy} \\ \hline
k-Means & k-Means clustering based on additive secret sharing. & \ac{SMPC}  & 
\cite{doganay2008distributed}                    \\\hline
\end{tabular}
\end{table}


\todo[inline]{maybe add logistic regression in this table?}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%